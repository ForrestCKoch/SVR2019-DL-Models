Dimensionality Reduction Notes
------------------------------

- [Zifa](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0805-z)
- [CIDR](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1188-0)
- [Component retention in principal component analysis with application to cDNA microarray data (2007)](https://biologydirect.biomedcentral.com/articles/10.1186/1745-6150-2-2)
  - Provides some good advice regarding how many components to retain in PCA

## Deep Learning Applications
- [Parameter tuning is a key part of dimensionality reduction via deep variational autoencoders for single cell RNA transcriptomics (2019)](https://www.worldscientific.com/doi/abs/10.1142/9789813279827_0033)
  - Very similar to the comparison I was thinking of doing
  - Uses Variational Autoencoders (VAEs)
  - Testing is only done on simulated datasets?
  - Finds that if VAE parameters are well chosen, the result is superior to existing methods
- [Using neural networks for reducing the dimensions of single-cell RNA-Seq data (2017)](https://academic.oup.com/nar/article/45/17/e156/4056711)
  - Uses very crude/trivial networks
- [Using autoencoders and text mining to characterize single cell populations in the hippocampus and cortex (2018)](https://ieeexplore.ieee.org/abstract/document/8374718)
  - DAE is used for feature extraction of each cluster, not for dimensionality reduction
- [Interpretable dimensionality reduction of single cell transcriptome data with deep generative models (2018)](https://www.nature.com/articles/s41467-018-04368-5)
  - Uses a "probabilistic generative model" (GAN/VAE?) for dimension reduction (scVis)
  - Intended for visualization, not necessarily accurate clustering???
- [Single cell RNA-seq denoising using a deep count autoencoder (2018)](https://www.biorxiv.org/content/biorxiv/early/2018/04/13/300681.full.pdf)
  - Proposes a "Deep Count Autoencoder (DCA)", which is effectively an SDAE, for imputing data
  > To test whether a ZINB loss function is necessary, we compared DCA to a classical autoencoder with mean squared error (MSE) loss function using log transformed count data. The MSE based autoencoder was unable to recover the celltypes, indicating that the specialized ZINB loss function is necessary for scRNA-seq data. 
  - Although, this could be due to poor parameter selection ...
  - Their bottle-neck layer is only 2!? Surely this causes big issues ...
- [Shallow Sparsely-Connected Autoencoders for Gene Set Projection (2019)](https://www.worldscientific.com/doi/abs/10.1142/9789813279827_0034)
  - Uses sparse (as opposed to dense) AEs for dimension reduction
  - Variational Autoencoders seemed to do a better job at generalizing to test sets
- [AutoImpute: Autoencoder based imputation of single-cell RNA-seq data(2018)](https://www.nature.com/articles/s41598-018-34688-x)
  - Uses a simple 3 layer (input->hidden->output), where the hidden layer is largest? (strange ...)
- [VASC: Dimension Reduction and Visualization of Single-cell RNA-seq Data by Deep Variational Autoencoder](https://www.sciencedirect.com/science/article/pii/S167202291830439X)
- [Bayesian deep learning for single-cell analysis](https://www.nature.com/articles/s41592-018-0230-9)
  - I'm not saying I know better, but I'd be pretty skeptical of a tool that refers to itself as a swiss army knife (never forget the UNIX philosophy to "Do one thing, well".
  
  
Preprocessing Notes
-------------------
- [Scater](https://academic.oup.com/bioinformatics/article/33/8/1179/2907823)
- Lin 2017 normalizes data by converting to Transcripts Per Million (TPM)
  - After normalization and imputation, each gene was normalized to a standard normal distribution
    - They claim this is an essential step for NN training???
    - We are working with count data here -- why should we expect this to follow a gaussian?  Surely a Poisson or Negative Binomial is more appropriate?
 - [Normalizing single-cell RNA sequencing data: Challenges and opportunities](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5549838/)
  - compares TPM, DESeq, and TMM
  - also touches on "scRNA" developed methods
    - SCDE and MAST
    - BASiCS
  - addresses how analyses can be affected further downstream by choice of normalization
