Some Notes
-----------

* There currently exist a pleathora of methods which can be used to obtain clustering
	* Some are generalized ML methods
	* Some are 'specialized' for single cell (although I would argue many are just a rebranding of existing techniques)

* Clustering algorithms tend to be anti-conservative
	* They are very good at detecting patterns that do exist
	* However, they have a tendancy to also detect patterns that don't exist

* Each algorithm will have it's own tendancies and biases
	* One method to help identify these is to use internal validation measures
		* Compactness
		* Connectedness
		* Spatial Separation
		* Combinations
			* Dunn Index (Dunn 1974)
			* Davids-Bouldin Index (1979)
			* Silhouette Width (Rousseeuw 1987)
		* Predictive power/stability
			* Ben-Hurr 2002
			* Bittner 2000
			* Brechenridge 1989
			* Fridlyand & Dudoit 2001
			* Kerr and Churchill 2001
			* Lange 2004
			* Levine & Domany 2001
			* Li and Wong 2001
			* McShane 2002
			* Tibshirani 2001 **
		* "Compliance between partitioning and distance information"
			* Romesburg 1984

* Handl 2005 provides some advice for performing clustering analyses
	* Use multiple clustering algorithms/approaches
		* If a cluster persistently exists between algorithms with different clustering tendancies, it may be more likely to exist
		* Hence applying a consensus algorithm may provide more realistic results

Practical Approach/Ideas
------------------------
* We apply a variety of [clustering algorithms](https://scikit-learn.org/stable/modules/clustering.html)
* We can also experiment with different dimensionality reduction techniques
	* UMAP
	* t-SNE (cannot be applied to new data)
	* SDAE
	* ... ?
* Compare each of the resulting clusterings
	* [Adjusted Rand Index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html) (ARI)
	* [Normalized Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html) (NMI ... There is also a version that is adjusted for chance similar to ARI)
	* Visualization
		* We can further reduce the number of dimensions to 2, and color using the results of various clustering algorithms to show similarities/differences

Remaining Issues
----------------
* What clustering algorithms to use
* What dimensionality reduction techniques to use
	* How do different dimensionality techniques affect clustering
* How many dimensions to reduce to
	* How does a different # of dimensions affect clustering

Note: Paukkeri 2011 (Effect of Dimensionality Reduction on Different Distance Measures in Document Clustering) may be of interest
